
@book{rfg,
	address = {New York},
	series = {Springer Monographs in Mathematics},
	title = {Random fields and geometry},
	isbn = {978-0-387-48112-8},
	url = {http://www.springer.com/978-0-387-48112-8},
	publisher = {Springer},
	author = {Adler, Robert J. and Taylor, Jonathan E.},
	year = {2007}
},



@article{lars,
	title = {Least angle regression},
	volume = {32},
	number = {2},
	journal = {Annals of Statistics},
	author = {Efron, Bradley and Hastie, Trevor and Johnstone, Iain and Tibshirani, Robert},
	year = {2004},
	pages = {407-–499}
},



@article{javanmard:montanari,
        author = {{Javanmard}, A. and {Montanari}, A.},
        title = {Hypothesis Testing in High-Dimensional Regression under the Gaussian Random Design Model: Asymptotic Theory},
        journal = {ArXiv e-prints},
        archivePrefix = "arXiv",
        eprint = {1301.4240},
        primaryClass = "stat.ME",
        keywords = {Statistics - Methodology, Computer Science - Information Theory, Mathematics - Statistics Theory, Statistics - Machine Learning},
        year = 2013,
        month = jan,
        adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1301.4240J},
        adsnote = {Provided by the SAO/NASA Astrophysics Data System}
},



@article{significance:lasso,
	title = {A significance test for the lasso},
	url = {http://arxiv.org/abs/1301.7161},
	abstract = {In the sparse linear regression setting, we consider testing the significance of the predictor variable that enters the current lasso model, in the sequence of models visited along the lasso solution path. We propose a simple test statistic based on lasso fitted values, called the \{{\textbackslash}it covariance test statistic\}, and show that when the true model is linear, this statistic has an \${\textbackslash}Exp(1)\$ asymptotic distribution under the null hypothesis (the null being that all truly active variables are contained in the current lasso model). Our proof of this result assumes some (reasonable) regularity conditions on the predictor matrix {\$X\$}, and covers the important high-dimensional case \$p{\textgreater}n\$. Of course, for testing the significance of an additional variable between two nested linear models, one may use the usual chi-squared test, comparing the drop in residual sum of squares ({RSS)} to a \${\textbackslash}chi{\textasciicircum}2\_1\$ distribution. But when this additional variable is not fixed, but has been chosen adaptively or greedily, this test is no longer appropriate: adaptivity makes the drop in {RSS} stochastically much larger than \${\textbackslash}chi{\textasciicircum}2\_1\$ under the null hypothesis. Our analysis explicitly accounts for adaptivity, as it must, since the lasso builds an adaptive sequence of linear models as the tuning parameter \${\textbackslash}lambda\$ decreases. In this analysis, shrinkage plays a key role: though additional variables are chosen adaptively, the coefficients of lasso active variables are shrunken due to the \${\textbackslash}ell\_1\$ penalty. Therefore the test statistic (which is based on lasso fitted values) is in a sense balanced by these two opposing properties---adaptivity and shrinkage---and its null distribution is tractable and asymptotically \${\textbackslash}Exp(1)\$.},
	urldate = {2013-01-31},
	journal = {{arXiv:1301.7161}},
	author = {Lockhart, Richard and Taylor, Jonathan and Tibshirani, Ryan and Tibshirani, Robert},
	month = jan,
	year = {2013},
	keywords = {{62J07}, {62F03}, Mathematics - Statistics Theory, Statistics - Methodology},
        note = {Submitted to Annals of Statistics}
},


@article{tests:adaptive,
        author = {{Taylor}, J. and {Loftus}, J. and {Tibshirani}, R.},
        title = {Tests in adaptive regression via the Kac-Rice formula},
        journal = {ArXiv e-prints},
        archivePrefix = "arXiv",
        eprint = {1308.3020},
        primaryClass = "stat.ME",
        keywords = {Statistics - Methodology},
        year = 2013,
        month = aug,
        adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1308.3020T},
        adsnote = {Provided by the SAO/NASA Astrophysics Data System}
},



@article{taylor:validity,
	title = {Validity of the expected Euler characteristic heuristic},
	volume = {33},
	issn = {0091-1798},
	number = {4},
	journal = {The Annals of Probability},
	author = {Taylor, {J.E.} and Takemura, A. and Adler, {R.J.}},
	year = {2005},
	pages = {1362-–1396}
},



@article{tibshirani:lasso,
	title = {Regression shrinkage and selection via the lasso},
	volume = {58},
	number = {1},
	journal = {Journal of the Royal Statistical Society: Series B},
	author = {Tibshirani, Robert},
	year = {1996},
	pages = {267-–288}
},



@article{grouplasso,
	title = {Model selection and estimation in regression with grouped variables},
	volume = {68},
	number = {1},
	journal = {Journal of the Royal Statistical Society: Series B},
	author = {Ming, Yuan and Lin, Yi},
	year = {2005},
	pages = {49-–67}
},


@ARTICLE{sequential:fdr,
   author = {{Grazier G'Sell}, M. and {Wager}, S. and {Chouldechova}, A. and {Tibshirani}, R.},
   title = "{False Discovery Rate Control for Sequential Selection Procedures, with Application to the Lasso}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1309.5352},
 primaryClass = "math.ST",
 keywords = {Mathematics - Statistics Theory, Statistics - Methodology},
     year = 2013,
    month = sep,
   adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1309.5352G},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
}

@article{RIC,
     jstor_articletype = {research-article},
     title = {The Risk Inflation Criterion for Multiple Regression},
     author = {Foster, Dean P. and George, Edward I.},
     journal = {The Annals of Statistics},
     jstor_issuetitle = {},
     volume = {22},
     number = {4},
     jstor_formatteddate = {Dec., 1994},
     pages = {pp. 1947-1975},
     url = {http://www.jstor.org/stable/2242493},
     ISSN = {00905364},
     abstract = {A new criterion is proposed for the evaluation of variable selection procedures in multiple regression. This criterion, which we call the risk inflation, is based on an adjustment to the risk. Essentially, the risk inflation is the maximum increase in risk due to selecting rather than knowing the "correct" predictors. A new variable selection procedure is obtained which, in the case of orthogonal predictors, substantially improves on AIC, Cp and BIC and is close to optimal. In contrast to AIC, Cp and BIC which use dimensionality penalties of 2, 2 and log n, respectively, this new procedure uses a penalty 2 log p, where p is the number of available predictors. For the case of nonorthogonal predictors, bounds for the optimal penalty are obtained.},
     language = {English},
     year = {1994},
     publisher = {Institute of Mathematical Statistics},
     copyright = {Copyright © 1994 Institute of Mathematical Statistics},
     annote = {Risk inflation improves on Cp, AIC, BIC (if ortho X), using 2log(p)}
}

@article{BIC,
     jstor_articletype = {research-article},
     title = {Estimating the Dimension of a Model},
     author = {Gideon Schwarz},
     journal = {The Annals of Statistics},
     jstor_issuetitle = {},
     volume = {6},
     number = {2},
     jstor_formatteddate = {Mar., 1978},
     pages = {pp. 461-464},
     url = {http://www.jstor.org/stable/2958889},
     ISSN = {00905364},
     abstract = {The problem of selecting one of a number of models of different dimensions is treated by finding its Bayes solution, and evaluating the leading terms of its asymptotic expansion. These terms are a valid large-sample criterion beyond the Bayesian context, since they do not depend on the a priori distribution.},
     language = {English},
     year = {1978},
     publisher = {Institute of Mathematical Statistics},
     copyright = {Copyright © 1978 Institute of Mathematical Statistics},
     annote = {First BIC paper},
}

@ARTICLE{donoho:pursuit, 
author={Donoho, D.L. and Elad, M. and Temlyakov, V.N.}, 
journal={Information Theory, IEEE Transactions on}, 
title={Stable recovery of sparse overcomplete representations in the presence of noise}, 
year={2006}, 
volume={52}, 
number={1}, 
pages={6-18}, 
keywords={approximation theory;iterative methods;signal denoising;signal representation;time-frequency analysis;Kruskal rank;greedy approximation algorithm;incoherent dictionary;matching pursuit;noisy data;optimal sparse decomposition;signal processing theory;sparse overcomplete representation;stable recovery;stepwise regression;superresolution signal;Dictionaries;Linear algebra;Matching pursuit algorithms;Noise generators;Noise level;Signal processing;Signal processing algorithms;Signal representations;Stability;Vectors;Basis pursuit;Kruskal rank;greedy approximation;incoherent dictionary;matching pursuit;overcomplete representation;sparse representation;stability;stepwise regression;superresolution}, 
doi={10.1109/TIT.2005.860430}, 
ISSN={0018-9448},
annote={Donoho paper, matching pursuit can give perfect recovery under an incoherence assumption, highly cited},
}

@ARTICLE{matching:pursuit, 
author={Mallat, S.G. and Zhang, Z.}, 
journal={Signal Processing, IEEE Transactions on}, 
title={Matching pursuits with time-frequency dictionaries}, 
year={1993}, 
volume={41}, 
number={12}, 
pages={3397-3415}, 
keywords={signal processing;time-frequency analysis;wavelet transforms;Gabor functions;adaptive signal representations;adaptive time-frequency transform;linear waveform expansion;matching pursuit algorithm;matching pursuit decomposition;noisy signals;optimized wavepacket orthonormal basis;pattern extraction;signal energy distribution;signal expansion;signal structures;time-frequency dictionaries;time-frequency plane;Dictionaries;Fourier transforms;Interference;Matching pursuit algorithms;Natural languages;Pursuit algorithms;Signal processing algorithms;Signal representations;Time frequency analysis;Vocabulary}, 
doi={10.1109/78.258082}, 
ISSN={1053-587X},
annote={Signal processing community, origin of name matching pursuit, highly cited, overcomplete dictionaries of wave functions},
}

@article{fdr,
  title={Controlling the false discovery rate: a practical and powerful approach to multiple testing},
  author={Benjamini, Yoav and Hochberg, Yosef},
  journal={Journal of the Royal Statistical Society. Series B (Methodological)},
  pages={289--300},
  year={1995},
  publisher={JSTOR}
}